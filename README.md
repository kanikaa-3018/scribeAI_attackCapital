
# **ScribeAI â€” AI-Powered Meeting Transcription & Summary Tool**

Transform your conversations into intelligent transcripts with real-time speech recognition and AI-powered summaries. Built with Next.js, Socket.IO, and Google Gemini AI.

---

## ğŸ“‘ **Table of Contents**
- [Overview](#overview)  
- [Features](#features)  
- [Tech Stack](#tech-stack)  
- [Architecture & Data Flow](#architecture--data-flow)  
- [Database Schema](#database-schema)  
- [Project Structure](#project-structure)  
- [Installation](#installation)  
- [Environment Variables](#environment-variables)  
- [Usage](#usage)  
- [API Endpoints](#api-endpoints)  
- [Transcription Services](#transcription-services)  
- [Authentication](#authentication)  
- [Deployment](#deployment)  
- [Contributing](#contributing)  
- [License](#license)

---

# ğŸš€ **Overview**

**ScribeAI** is a modern, AI-powered transcription platform that makes recording and processing conversations effortless. Whether you're in a meeting, interview, or brainstorming session, ScribeAI captures everything and delivers:

- **Real-time transcription** using browser Speech Recognition API
- **AI-generated summaries** with structured titles, bullets, and keywords via Google Gemini
- **Tab audio recording** for capturing browser content (videos, calls, presentations)
- **Microphone recording** with live transcription for in-person conversations
- **Session management** with search, filtering, and export capabilities
- **Privacy-first design** with optional cloud transcription via AssemblyAI/Deepgram

**No signup required to start recording!**

---

# âœ¨ **Features**

## ğŸ™ï¸ **Recording Capabilities**
- **Microphone Recording** with live browser-based transcription
- **Tab/Share Audio** capture for recording browser tabs, system audio
- **Visual audio analyzer** showing real-time waveforms
- **Automatic chunk management** for reliable, resumable recordings
- **Pause/Resume** functionality during recording
- **Multiple audio device support** (includes VB-Audio, Stereo Mix loopback)

## ğŸ¤– **AI-Powered Intelligence**
- **Real-time transcription** using Web Speech API (completely free)
- **AI Summaries** generated by Google Gemini AI
- **Smart keyword extraction** for quick session categorization
- **Structured output** with titles, bullets, and action items
- **Server-side transcription** via AssemblyAI for tab audio (free tier: 100 hours/month)

## ğŸ“Š **Session Management**
- **Session History** with pagination and real-time updates
- **Search & Filter** by keywords, content, and dates
- **Session Details** page with full transcript and summary
- **Export Options**: Plain text, Markdown, SRT subtitles
- **Audio Playback** from concatenated chunks
- **Delete Sessions** with one click

## ğŸ¨ **Modern UI/UX**
- **Neubrutalism design** with bold colors and thick borders
- **Responsive layout** that works on all screen sizes
- **Dark mode ready** with CSS custom properties
- **Smooth animations** and transitions
- **Toast notifications** for user feedback
- **Loading states** and error handling

## ğŸ”’ **Authentication & Security**
- **Optional authentication** - use without signup
- **JWT-based auth** with bcrypt password hashing
- **User profiles** with email and name
- **Session ownership** tracking
- **Logout functionality** with token cleanup

---

# ğŸ›  **Tech Stack**

### **Frontend**
- **Next.js 14** (App Router with TypeScript)
- **React 18** with hooks and context
- **TailwindCSS** for utility-first styling
- **Socket.IO Client** for real-time communication
- **Web Speech API** for browser-based transcription
- **MediaRecorder API** for audio capture

### **Backend**
- **Node.js** with TypeScript
- **Socket.IO** for WebSocket connections
- **Express.js** for REST API
- **Prisma ORM** with PostgreSQL
- **JWT** for authentication
- **bcryptjs** for password hashing

### **AI & Transcription**
- **Google Gemini AI** for summaries and text generation
- **AssemblyAI** for high-quality audio transcription
- **Deepgram** as fallback transcription service
- **Browser Speech Recognition** for free real-time transcription

### **Storage**
- **PostgreSQL** for session data
- **Local filesystem** for audio chunks
- **JSON files** as fallback storage

---

# ğŸ“ **Architecture & Data Flow**

```mermaid
flowchart TB
    subgraph Client["ğŸ–¥ï¸ Browser Client"]
        A[User Interface] --> B[Recording Panel]
        B --> C{Audio Source?}
        C -->|Microphone| D[getUserMedia]
        C -->|Tab/Share| E[getDisplayMedia]
        D --> F[MediaRecorder]
        E --> F
        F --> G[Audio Chunks]
        H[Speech Recognition] --> I[Live Transcript]
    end
    
    subgraph Server["âš¡ Socket.IO Server"]
        G -->|WebSocket| J[Chunk Handler]
        J --> K[Save to Disk]
        K --> L[recordings/session-id/]
        I -->|Final| M[Transcript Processor]
        M --> N{Has Transcript?}
        N -->|No| O[AssemblyAI API]
        N -->|Yes| P[Gemini AI]
        O --> P
        P --> Q[Generate Summary]
        Q --> R[Save to Database]
    end
    
    subgraph Storage["ğŸ’¾ Data Storage"]
        L --> S[(File System)]
        R --> T[(PostgreSQL)]
    end
    
    subgraph API["ğŸ”Œ REST API"]
        U[GET /api/sessions] --> T
        V[POST /api/sessions] --> T
        W[DELETE /api/sessions/:id] --> T
        W --> S
    end
    
    A --> U
    R --> X[Session Saved Event]
    X --> A
    
    style Client fill:#e9f7ef
    style Server fill:#fff0da
    style Storage fill:#f0f9ff
    style API fill:#fef3c7
```

---

# ğŸ—„ **Database Schema**

```mermaid
erDiagram
    User ||--o{ Session : owns
    Session ||--o{ Recording : contains
    
    User {
        string id PK
        string email UK
        string name
        string password
        datetime createdAt
        datetime updatedAt
    }
    
    Session {
        string id PK
        string clientSessionId UK
        string title
        string transcript
        string summary
        string status
        datetime startedAt
        datetime endedAt
        string downloadUrl
        string ownerId FK
        string[] keywords
    }
    
    Recording {
        string path
        int chunkCount
        int totalSize
    }
```

**Key Models:**
- **User**: Authentication and ownership
- **Session**: Recording metadata, transcripts, summaries
- **Keywords**: Auto-extracted for search/filtering

---

# ğŸ“ **Project Structure**

```
attack-capital/
â”œâ”€â”€ app/                          # Next.js App Router
â”‚   â”œâ”€â”€ (auth)/
â”‚   â”‚   â””â”€â”€ login/
â”‚   â”‚       â””â”€â”€ page.tsx         # Login/Signup page
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ ping/
â”‚   â”‚   â”‚   â””â”€â”€ route.ts        # Health check
â”‚   â”‚   â””â”€â”€ sessions/
â”‚   â”‚       â”œâ”€â”€ route.ts        # List/Create sessions
â”‚   â”‚       â””â”€â”€ [id]/
â”‚   â”‚           â”œâ”€â”€ route.ts    # Delete session
â”‚   â”‚           â””â”€â”€ export/
â”‚   â”‚               â””â”€â”€ route.ts # Export transcript
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ Navbar.tsx          # Navigation with auth
â”‚   â”‚   â”œâ”€â”€ RecordingPanel.tsx  # Main recording UI
â”‚   â”‚   â”œâ”€â”€ SessionHistory.tsx  # Session list with delete
â”‚   â”‚   â””â”€â”€ Toast.tsx           # Notifications
â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â””â”€â”€ page.tsx            # Recording dashboard
â”‚   â”œâ”€â”€ sessions/
â”‚   â”‚   â”œâ”€â”€ page.tsx            # All sessions (recordings)
â”‚   â”‚   â””â”€â”€ [id]/
â”‚   â”‚       â””â”€â”€ page.tsx        # Session detail view
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ summaries/
â”‚   â”‚   â”‚   â””â”€â”€ page.tsx        # AI summaries browser
â”‚   â”‚   â””â”€â”€ transcripts/
â”‚   â”‚       â””â”€â”€ page.tsx        # Transcript search
â”‚   â”œâ”€â”€ globals.css             # Global styles + neubrutalism
â”‚   â”œâ”€â”€ layout.tsx              # Root layout
â”‚   â””â”€â”€ page.tsx                # Landing page
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ gemini.ts               # Gemini AI integration
â”œâ”€â”€ prisma/
â”‚   â”œâ”€â”€ schema.prisma           # Database schema
â”‚   â””â”€â”€ migrations/             # DB migrations
â”œâ”€â”€ recordings/                  # Audio chunk storage
â”‚   â””â”€â”€ session-*/
â”‚       â”œâ”€â”€ *.webm              # Audio chunks
â”‚       â””â”€â”€ transcript.txt      # Generated transcript
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ index.ts                # Express + Socket.IO server
â”‚   â”œâ”€â”€ gemini.js               # AI summary & transcription
â”‚   â”œâ”€â”€ users.json              # User data (demo)
â”‚   â””â”€â”€ sockets/
â”‚       â””â”€â”€ recording.ts        # WebSocket handlers
â”œâ”€â”€ types/                       # TypeScript declarations
â”œâ”€â”€ .env                         # Environment variables
â”œâ”€â”€ next.config.js
â”œâ”€â”€ package.json
â”œâ”€â”€ tailwind.config.js
â””â”€â”€ tsconfig.json
```

---

# âš™ï¸ **Installation**

### **Prerequisites**
- **Node.js 18+** and npm
- **PostgreSQL 12+** (or use the fallback JSON storage)
- **Git**

### **1. Clone the Repository**
```bash
git clone https://github.com/yourusername/attack-capital.git
cd attack-capital
```

### **2. Install Dependencies**
```bash
npm install
```

### **3. Set Up Database**
```bash
# Start PostgreSQL (Windows with Docker)
docker run -d -p 5433:5432 -e POSTGRES_PASSWORD=password postgres

# Run Prisma migrations
npx prisma migrate dev
npx prisma generate
```

### **4. Configure Environment**
Create a `.env` file in the root:
```env
DATABASE_URL=postgresql://user:password@localhost:5433/attack_capital
GEMINI_API_KEY=your_gemini_api_key_here
ASSEMBLYAI_API_KEY=your_assemblyai_key_here
DEEPGRAM_API_KEY=your_deepgram_key_here
NEXTAUTH_SECRET=your_secret_key_here
GEMINI_PROVIDER=google
GEMINI_MODEL=gemini-2.5-flash
```

### **5. Start Development Servers**
```bash
npm run dev
```

This starts:
- **Frontend**: http://localhost:3000
- **Socket Server**: http://localhost:4000

---

# ğŸ” **Environment Variables**

| Variable | Required | Description | Default |
|----------|----------|-------------|---------|
| `DATABASE_URL` | Optional | PostgreSQL connection string | File storage fallback |
| `GEMINI_API_KEY` | Yes | Google AI Studio API key for summaries | - |
| `ASSEMBLYAI_API_KEY` | Optional | AssemblyAI key for tab audio transcription | - |
| `DEEPGRAM_API_KEY` | Optional | Deepgram fallback transcription | - |
| `NEXTAUTH_SECRET` | Yes | Secret for JWT signing | Random string |
| `GEMINI_PROVIDER` | Optional | AI provider (`google`) | `google` |
| `GEMINI_MODEL` | Optional | Gemini model name | `gemini-2.5-flash` |

**Get API Keys:**
- **Gemini AI**: https://aistudio.google.com/app/apikey
- **AssemblyAI**: https://www.assemblyai.com/dashboard/signup (100 hours/month free)
- **Deepgram**: https://console.deepgram.com/signup (45k minutes/month free)

---

# ğŸ–¥ï¸ **Usage**

### **1. Start Recording**
1. Visit http://localhost:3000
2. Click **"Start Recording Now"** or go to Dashboard
3. Select audio source:
   - **Microphone**: For live speech with real-time transcription
   - **Tab/Share**: For capturing browser audio (YouTube, Zoom, etc.)
4. Choose your audio input device from the dropdown
5. Click **â–¶ Start**

### **2. During Recording**
- Watch the **live transcript** appear (microphone mode only)
- See **audio levels** in the visualizer
- Use **Pause/Resume** as needed
- Click **â–  Stop** when done

### **3. After Recording**
- AI automatically generates a **summary** with title and bullets
- View the session in **Session History**
- Click **ğŸ“„ Transcript** or **âœ¨ Summary** to view details
- Use **View Details** to see the full session page
- **Export** transcript as Text, Markdown, or SRT

### **4. Tab Audio Setup (Windows)**
For transcribing tab audio:
1. Enable **"Stereo Mix"** in Windows Sound Settings â†’ Recording
2. Or install **VB-Audio Virtual Cable** (free)
3. Set system to route audio through the loopback device
4. Select **Microphone** mode with the loopback device
5. Now tab audio will be transcribed in real-time!

---

# ğŸ”Œ **API Endpoints**

### **REST API**

| Method | Endpoint | Description | Auth |
|--------|----------|-------------|------|
| `GET` | `/api/sessions` | List all sessions (paginated) | Optional |
| `POST` | `/api/sessions` | Create/update session | Optional |
| `DELETE` | `/api/sessions/:id` | Delete session and recordings | Optional |
| `GET` | `/api/sessions/:id/audio` | Stream concatenated audio | No |
| `GET` | `/api/sessions/:id/export` | Download transcript | No |
| `GET` | `/api/ping` | Health check | No |

### **Socket.IO Events**

**Client â†’ Server:**
- `startSession(data)` - Initialize new recording session
- `audioChunk(data)` - Send audio blob chunk
- `stopSession(data)` - End session and process

**Server â†’ Client:**
- `connect` - Socket connected
- `transcriptUpdate(data)` - Real-time transcript updates
- `sessionSaved(data)` - Session persisted to DB

---

# ğŸ§  **Transcription Services**

### **1. Browser Speech Recognition (Free)**
- **Best for**: Microphone recordings, live meetings
- **Pros**: Instant, no API costs, works offline
- **Cons**: Only works with microphone input, language-dependent
- **Setup**: No configuration needed

### **2. AssemblyAI (Recommended for Tab Audio)**
- **Best for**: High-quality transcription of recordings
- **Free Tier**: 100 hours/month
- **Pros**: Excellent accuracy, supports WebM format
- **Cons**: Requires API key, async processing
- **Setup**: Add `ASSEMBLYAI_API_KEY` to `.env`

### **3. Deepgram (Fallback)**
- **Best for**: Real-time streaming transcription
- **Free Tier**: 45,000 minutes/month
- **Pros**: Fast processing, good accuracy
- **Cons**: Some WebM codec issues
- **Setup**: Add `DEEPGRAM_API_KEY` to `.env`

---

# ğŸ” **Authentication**

ScribeAI uses JWT-based authentication:

### **Login/Signup**
```typescript
POST http://localhost:4000/auth/signup
{
  "name": "John Doe",
  "email": "john@example.com",
  "password": "secure123"
}

Response:
{
  "ok": true,
  "token": "eyJhbGc...",
  "user": { "email": "john@example.com", "name": "John Doe" }
}
```

### **Get User Profile**
```typescript
GET http://localhost:4000/auth/me
Headers: { Authorization: "Bearer <token>" }
```

### **Logout**
```typescript
POST http://localhost:4000/auth/logout
Headers: { Authorization: "Bearer <token>" }
```

Tokens are stored in `localStorage` as `scribeai_token`.

---

# ğŸš€ **Deployment**

### **Build for Production**
```bash
npm run build
npm run build:server
```

### **Start Production**
```bash
npm start
```

### **Deploy to Vercel (Frontend)**
```bash
vercel
```

### **Deploy Server (Railway/Render)**
1. Set environment variables
2. Deploy from GitHub
3. Use build command: `npm run build:server`
4. Use start command: `node dist/server/index.js`

---

# ğŸ§ª **Testing**

### **Test Database Connection**
```bash
node scripts/test-db-conn.js
```

### **Test Session API**
```bash
node scripts/test-post-session.js
```

### **Test Transcription**
```bash
node scripts/test-transcribe.js
```

---

# ğŸ¤ **Contributing**

We welcome contributions! Here's how:

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **Push** to the branch (`git push origin feature/amazing-feature`)
5. **Open** a Pull Request

**Code Style:**
- Run `npm run lint` before committing
- Use TypeScript for all new code
- Follow existing patterns and conventions
- Add comments for complex logic

---

# ğŸ“„ **License**

MIT License - see [LICENSE](LICENSE) file for details.

---

# ğŸ™ **Acknowledgments**

Built with:
- [Next.js](https://nextjs.org/)
- [Socket.IO](https://socket.io/)
- [Google Gemini AI](https://ai.google.dev/)
- [AssemblyAI](https://www.assemblyai.com/)
- [Prisma](https://www.prisma.io/)
- [TailwindCSS](https://tailwindcss.com/)

---

# ğŸ“§ **Support**

For issues, questions, or feature requests, please open an issue on GitHub.

**Made with â¤ï¸ by the ScribeAI Team**



